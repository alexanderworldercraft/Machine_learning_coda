# Machine_learning_coda

![IA](./asset/ia.webp "Image illustrant l'IA.")

## Sommaire :

- [**Jour 1Ô∏è‚É£ : Grands concepts, machine learning supervis√©, introduction aux outils.**](#jour-1Ô∏è‚É£--grands-concepts-machine-learning-supervis√©-introduction-aux-outils)
  - [Qu'est ce que le machine learning ?](#quest-ce-que-le-machine-learning-)
  - [kaggle](#kaggle)
    - [Qu'est ce que le site kaggle ?](#quest-ce-que-le-site-keggle-)
- [**Jour 2Ô∏è‚É£ : Machine learning non supervis√©, corr√©lation et causalit√©, explicabilit√©.**](#jour-2Ô∏è‚É£--machine-learning-non-supervis√©-corr√©lation-et-causalit√©-explicabilit√©)
  - [Exemple de mod√®les avanc√©s](#exemple-de-mod√®les-avanc√©s)
  - [les For√™ts Al√©atoires](#les-for√™ts-al√©atoires)
    - [Comment fonctionnent les For√™ts Al√©atoires ?](#comment-fonctionnent-les-for√™ts-al√©atoires-)
    - [Avantages des For√™ts Al√©atoires](#avantages-des-for√™ts-al√©atoires)
    - [Limitations des For√™ts Al√©atoires](#limitations-des-for√™ts-al√©atoires)
    - [Applications des For√™ts Al√©atoires](#applications-des-for√™ts-al√©atoires)
    - [Pourquoi les For√™ts Al√©atoires sont-elles efficaces ?](#pourquoi-les-for√™ts-al√©atoires-sont-elles-efficaces-)
  - [le Boosting]








- [**Jour 3Ô∏è‚É£ : Deep learning, vision par ordinateur, tra√Ætement du langage naturel.**](#jour-3Ô∏è‚É£--deep-learning-vision-par-ordinateur-tra√Ætement-du-langage-naturel)
- [**Jour 4Ô∏è‚É£ : LLMs et IA G√©n√©rative**](#jour-4Ô∏è‚É£--llms-et-ia-g√©n√©rative)
- [**jour 5Ô∏è‚É£ : Les m√©tiers de la Data et de l‚ÄôIA, IA & √©thique, conclusion du challenge**](#jour-5Ô∏è‚É£--les-m√©tiers-de-la-data-et-de-lia-ia--√©thique-conclusion-du-challenge)

- [**ü§ñ Challenge**]()
  - [Pr√©dire la vitesse d'adoption d'animaux de compagnie en fonction de l'annonce post√©e.]()
  - [Recommander aux sauveteurs d'animaux des strat√©gies pour optimiser les annnonces d'adoption.]()
  - [Fournir un code que les √©quipes vont pouvoir reprendre, industrialiser et am√©liorer avec moins d'effort possible.]()

- [**üïµÔ∏è‚Äç‚ôÇÔ∏è Liens utile**](#liens-utile)






- [**üèÅ Conclusion**](#conclusion)
- [**ü•á Contribution**](#contribution)
  - [üë¶ Contribueur](#contribueur)
- [**üìÑ Licence**](#licence)

## Jour 1Ô∏è‚É£ : Grands concepts, Machine Learning supervis√©, introduction aux outils

### Qu'est ce que le machine learning ?

Le **Machine Learning (apprentissage automatique)** est un sous-domaine de l'intelligence artificielle (IA) qui consiste √† cr√©er des syst√®mes capables d'apprendre √† partir de donn√©es sans √™tre explicitement programm√©s pour une t√¢che sp√©cifique. En d'autres termes, au lieu de coder un programme pour r√©soudre un probl√®me, on fournit √† l'algorithme des exemples (donn√©es d'entra√Ænement), et il apprend √† reconna√Ætre des motifs ou des r√©gularit√©s dans ces donn√©es pour ensuite faire des pr√©dictions ou des d√©cisions sur des donn√©es nouvelles.

Il existe trois types principaux d'apprentissage automatique :

1. **Apprentissage supervis√©** : L'algorithme apprend √† partir d'exemples √©tiquet√©s (`donn√©es avec la r√©ponse correcte`). Ex : reconnaissance d'images, pr√©diction de prix. (Ne change pas de comportement).

2. **Apprentissage non supervis√©** : L'algorithme essaie de trouver des structures ou des motifs dans des donn√©es `non √©tiquet√©es`. Ex : clustering, r√©duction de dimensionnalit√©. (Peux chang√© de comportement).

3. **Apprentissage par renforcement** : L'algorithme apprend √† `prendre des d√©cisions en interagissant avec un environnement` et en recevant des r√©compenses ou des punitions en fonction de ses actions. Ex : jeux vid√©o (**vid√©o IA sur Track mania**), robots. (Commence sans donn√©es.)

Le machine learning est utilis√© dans divers domaines comme la reconnaissance d'image, la recommandation de produits, le traitement du langage naturel, et bien plus encore.


## kaggle

lien du site [ici](https://www.kaggle.com/).

### Qu'est ce que le site Keggle ?

Kaggle est une plateforme en ligne sp√©cialis√©e dans le **data science** et le **machine learning**. Voici ses principales fonctionnalit√©s :

1. **Comp√©titions** : Kaggle est surtout connu pour ses comp√©titions de machine learning, o√π des entreprises et des chercheurs publient des ensembles de donn√©es et des probl√®mes √† r√©soudre. Les participants soumettent leurs mod√®les, et les meilleurs mod√®les sont souvent r√©compens√©s par des prix en argent.

2. **Datasets** : Kaggle fournit une vaste collection de jeux de donn√©es gratuits que les utilisateurs peuvent explorer, analyser et utiliser pour leurs projets personnels ou professionnels.

3. **Kernels (Notebooks)** : Les utilisateurs peuvent cr√©er des notebooks (souvent en Python ou R) directement sur la plateforme pour effectuer des analyses de donn√©es, entra√Æner des mod√®les, et visualiser des r√©sultats. Il n'est pas n√©cessaire de t√©l√©charger les jeux de donn√©es sur son propre ordinateur, tout peut se faire en ligne.

4. **Apprentissage** : Kaggle propose des tutoriels et des cours gratuits pour apprendre des comp√©tences en data science, en machine learning et en intelligence artificielle, allant des bases √† des techniques avanc√©es.

5. **Communaut√©** : La plateforme abrite une grande communaut√© d'experts en data science, ce qui permet aux utilisateurs de poser des questions, partager leurs id√©es, et collaborer sur des projets.

En r√©sum√©, Kaggle est un outil puissant pour tous ceux qui s'int√©ressent √† la **science des donn√©es**, du d√©butant au professionnel.


## Jour 2Ô∏è‚É£ : Machine Learning non supervis√©, corr√©lation et causalit√©, explicabilit√©
### Exemple de mod√®les avanc√©s
  - [mod√®les avanc√©s du prof](./asset/Correction%20Mod√®les%20Avanc√©s.ipynb)
### les For√™ts Al√©atoires

**Les For√™ts Al√©atoires** (en anglais *Random Forests*) sont une m√©thode d'apprentissage automatique qui combine plusieurs arbres de d√©cision pour am√©liorer la pr√©cision des pr√©dictions et r√©duire le risque de surapprentissage (*overfitting*). Voici une explication plus d√©taill√©e de leur fonctionnement et de leurs avantages.

#### Comment fonctionnent les For√™ts Al√©atoires ?
1. **Construction de multiples arbres de d√©cision** : Une For√™t Al√©atoire est compos√©e de nombreux arbres de d√©cision individuels. Chaque arbre est construit √† partir d'un √©chantillon diff√©rent des donn√©es d'entra√Ænement.
2. **√âchantillonnage avec remise (Bootstrap)** : Pour chaque arbre, un sous-ensemble al√©atoire des donn√©es d'entra√Ænement est s√©lectionn√© avec remise. Cela signifie que certains √©chantillons peuvent √™tre choisis plusieurs fois pour un arbre donn√©, tandis que d'autres peuvent ne pas √™tre s√©lectionn√©s.
3. **S√©lection al√©atoire des caract√©ristiques** : Lors de la construction de chaque arbre, √† chaque n≈ìud, un sous-ensemble al√©atoire de caract√©ristiques est consid√©r√© pour d√©terminer la meilleure division. Cette technique ajoute de la diversit√© entre les arbres.
4. **Agr√©gation des pr√©dictions** :
    - **Pour la classification** : Chaque arbre "vote" pour une classe, et la classe la plus vot√©e est choisie comme pr√©diction finale.
    - **Pour la r√©gression** : La moyenne des pr√©dictions de tous les arbres est calcul√©e pour obtenir la pr√©diction finale.
#### Avantages des For√™ts Al√©atoires
- **Am√©lioration de la pr√©cision** : En combinant les pr√©dictions de multiples arbres, les For√™ts Al√©atoires atteignent g√©n√©ralement une meilleure performance que les arbres de d√©cision individuels.
- **R√©duction du surapprentissage** : Les arbres de d√©cision peuvent facilement surapprendre les donn√©es d'entra√Ænement. Les For√™ts Al√©atoires att√©nuent ce probl√®me gr√¢ce √† la diversit√© introduite par l'√©chantillonnage al√©atoire des donn√©es et des caract√©ristiques.
- **Robustesse aux donn√©es bruit√©es** : Elles sont moins sensibles aux anomalies et aux valeurs aberrantes dans les donn√©es.
- **Gestion efficace des grandes bases de donn√©es** : Elles peuvent g√©rer efficacement un grand nombre de caract√©ristiques et d'√©chantillons sans n√©cessiter beaucoup de pr√©traitement des donn√©es.
- **Estimation de l'importance des variables** : Les For√™ts Al√©atoires peuvent fournir une mesure de l'importance de chaque caract√©ristique dans la pr√©diction, aidant √† identifier les variables les plus influentes.
#### Limitations des For√™ts Al√©atoires
- **Perte d'interpr√©tabilit√©** : Contrairement √† un arbre de d√©cision unique, les For√™ts Al√©atoires sont plus difficiles √† interpr√©ter en raison du grand nombre d'arbres impliqu√©s.
- **Temps de calcul plus long** : Entra√Æner plusieurs arbres et agr√©ger leurs pr√©dictions peut √™tre plus gourmand en temps et en ressources informatiques.
- **Possibilit√© de biais** : Si les donn√©es contiennent des biais, les For√™ts Al√©atoires peuvent les reproduire, car elles n'ont pas de m√©canisme intrins√®que pour les corriger.
#### Applications des For√™ts Al√©atoires
Les For√™ts Al√©atoires sont utilis√©es dans de nombreux domaines en raison de leur efficacit√© et de leur flexibilit√© :
- **M√©decine** : Diagnostic de maladies, analyse g√©n√©tique.
- **Finance** : Pr√©diction de risques, d√©tection de fraudes.
- **Marketing** : Segmentation de client√®le, pr√©diction du comportement des consommateurs.
- **Environnement** : Pr√©vision m√©t√©orologique, mod√©lisation √©cologique.
- **Informatique** : Reconnaissance d'images, traitement du langage naturel.
#### Pourquoi les For√™ts Al√©atoires sont-elles efficaces ?
- **Diversification des mod√®les** : En entra√Ænant chaque arbre sur des donn√©es et des caract√©ristiques diff√©rentes, les For√™ts Al√©atoires cr√©ent une collection d'arbres vari√©s qui, ensemble, capturent une image plus compl√®te des donn√©es.
- **R√©duction de la variance** : La combinaison des pr√©dictions de plusieurs arbres r√©duit la variance globale du mod√®le, conduisant √† des pr√©dictions plus stables et fiables.
- **Principe de la "sagesse des foules"** : Comme un groupe d'experts peut prendre une meilleure d√©cision qu'un seul individu, une For√™t Al√©atoire utilise la sagesse collective de nombreux arbres pour am√©liorer la pr√©cision.
----
### le Boosting
Les **algorithmes de Boosting** sont une famille de m√©thodes d'apprentissage automatique qui visent √† am√©liorer la pr√©cision des pr√©dictions en combinant plusieurs mod√®les simples (appel√©s apprenants faibles) pour cr√©er un mod√®le puissant. L'id√©e fondamentale du Boosting est de construire un ensemble de mod√®les qui corrigent successivement les erreurs des pr√©c√©dents.
#### Comment fonctionne le Boosting ?
1. **Initialisation :**
    - On commence par entra√Æner un mod√®le de base sur l'ensemble des donn√©es d'entra√Ænement.
    - Ce mod√®le peut √™tre un arbre de d√©cision peu profond, appel√© "souche" (stump).
2. **Pond√©ration des observations :**
    - Apr√®s l'entra√Ænement du premier mod√®le, on √©value ses performances.
    - Les observations mal pr√©dites re√ßoivent un poids plus √©lev√©, ce qui signifie qu'elles seront davantage prises en compte lors de l'entra√Ænement du prochain mod√®le.
3. **It√©ration :**
    - Un nouveau mod√®le est entra√Æn√©, en se concentrant sur les observations qui ont √©t√© mal pr√©dites par le mod√®le pr√©c√©dent.
    - Ce processus est r√©p√©t√© plusieurs fois, chaque nouveau mod√®le tentant de corriger les erreurs des mod√®les ant√©rieurs.
4. **Combinaison des mod√®les :**
    - Les pr√©dictions finales sont obtenues en combinant les pr√©dictions de tous les mod√®les.
    - Pour la classification, cela peut se faire par un vote pond√©r√© ; pour la r√©gression, par une moyenne pond√©r√©e.
#### Types d'algorithmes de Boosting
1. **AdaBoost (Adaptive Boosting) :**
    - **Principe** : Ajuste les poids des observations √† chaque it√©ration en accordant plus d'importance aux erreurs.








## Jour 3Ô∏è‚É£ : Deep Learning, vision par ordinateur, tra√Ætement du langage naturel
## Jour 4Ô∏è‚É£ : LLMs et IA G√©n√©rative
## Jour 5Ô∏è‚É£ : Les m√©tiers de la Data et de l‚ÄôIA, IA & √©thique, conclusion du challenge
## Challenge
### Pr√©dire la vitesse d'adoption d'animaux de compagnie en fonction de l'annonce post√©e.
### Recommander aux sauveteurs d'animaux des strat√©gies pour optimiser les annnonces d'adoption.
### Fournir un code que les √©quipes vont pouvoir reprendre, industrialiser et am√©liorer avec moins d'effort possible.

# Liens utile

Liens des slides :
- [https://docs.google.com/presentation/d/1PfxoBpOC2gWMZONN5JIzRF1WzBcfEyEpeTJcHPQJc6Y/edit?usp=sharing](https://docs.google.com/presentation/d/1PfxoBpOC2gWMZONN5JIzRF1WzBcfEyEpeTJcHPQJc6Y/edit?usp=sharing) ou [`ici`](./asset/Introduction%20au%20Machine%20Learning.pdf)
- [https://docs.google.com/presentation/d/1Mdtt6g66YPeiun7eoobayZSmj5bxmX_fOWvSEaxGkeU/edit?usp=sharing](https://docs.google.com/presentation/d/1Mdtt6g66YPeiun7eoobayZSmj5bxmX_fOWvSEaxGkeU/edit?usp=sharing) ou [`ici`](./asset/Introduction.pdf)
- [https://docs.google.com/presentation/d/14fgS2g6At8xmurBJhkfYC_XaK2xDil2G5cGa6GOHUPw/edit#slide=id.p1](https://docs.google.com/presentation/d/14fgS2g6At8xmurBJhkfYC_XaK2xDil2G5cGa6GOHUPw/edit#slide=id.p1) ou [`ici`](./asset/Deep%20Learning%20et%20vision%20par%20ordinateur.pdf)

Liens des tutoriels Kaggle :
- [https://www.kaggle.com/learn/python](https://www.kaggle.com/learn/python)
- [https://www.kaggle.com/learn/pandas](https://www.kaggle.com/learn/pandas)
- [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning)
- [https://www.kaggle.com/learn/data-visualization](https://www.kaggle.com/learn/data-visualization)
- [https://www.kaggle.com/learn/data-cleaning](https://www.kaggle.com/learn/data-cleaning)
- [https://www.kaggle.com/learn/intermediate-machine-learning](https://www.kaggle.com/learn/intermediate-machine-learning)
- [https://www.kaggle.com/learn/feature-engineering](https://www.kaggle.com/learn/feature-engineering)

Lien du r√©po github : [https://github.com/vlandeau/data_dojo/tree/master](https://github.com/vlandeau/data_dojo/tree/master)

Lien de Google Colab : [https://colab.research.google.com/](https://colab.research.google.com/)

Lien du challenge : [https://www.kaggle.com/t/a893379e9b624b308e5151d9ab7ed1f2](https://www.kaggle.com/t/a893379e9b624b308e5151d9ab7ed1f2)

Lien d'explication des mod√®les : slide [https://docs.google.com/presentation/d/1AfYnGmOwGxwM4DJsmhzP4ucz9LQ9IJFmwkh8_Mx4W94/edit#slide=id.g1879f72834b_0_1198](https://docs.google.com/presentation/d/1AfYnGmOwGxwM4DJsmhzP4ucz9LQ9IJFmwkh8_Mx4W94/edit#slide=id.g1879f72834b_0_1198) ou [ici](/asset/Shapash.pdf)

Lien d'explication des mod√®les : colab [https://colab.research.google.com/drive/1D9-o6Nouv1M2NA8LDV3CFDORqHr1LoSd?usp=sharing](https://colab.research.google.com/drive/1D9-o6Nouv1M2NA8LDV3CFDORqHr1LoSd?usp=sharing)

Lien des features cat√©gorielles : [https://colab.research.google.com/drive/1eC9P_RGowpnSjfurUy-K0UwoUU9PUHRp?usp=sharing](https://colab.research.google.com/drive/1eC9P_RGowpnSjfurUy-K0UwoUU9PUHRp?usp=sharing)

Librairies utilis√©es :
- [Shapash](https://github.com/MAIF/shapash)
- [Shap](https://shap.readthedocs.io/en/latest/index.html)
- [category_encoders](https://contrib.scikit-learn.org/category_encoders/)

## üèÅ Conclusion

## Contribution

Les contributions √† ce repository sont les bienvenues ! Si vous souhaitez corriger une erreur ou am√©liorer le contenu existant, n'h√©sitez pas √† m'en faire part.

### Contribueur

- [**üë®‚Äçüíªü•á Alexander worldercraft**](https://github.com/alexanderworldercraft)

## Licence

Ce contenu est sous licence [GNU GPLv3](LICENSE.txt). Vous √™tes libre de l'utiliser, le modifier et le distribuer selon les termes de cette licence.